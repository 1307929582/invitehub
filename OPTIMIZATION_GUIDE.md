# ä¼ä¸šçº§é«˜å¹¶å‘ä¼˜åŒ–å®æ–½æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜äº†å¯¹ InviteHub é¡¹ç›®è¿›è¡Œçš„ä¼ä¸šçº§ä¼˜åŒ–ï¼Œä»¥æ”¯æŒå¤§è§„æ¨¡ç”¨æˆ·é«˜å¹¶å‘åœºæ™¯ã€‚

---

## ğŸ“‹ ä¼˜åŒ–æ¦‚è§ˆ

### å·²å®Œæˆçš„ä¼˜åŒ–

#### âœ… é˜¶æ®µä¸€ï¼šæ•°æ®åº“ä¼˜åŒ–ï¼ˆç´§æ€¥ä¿®å¤ï¼‰
- **models.py**: æ·»åŠ å…³é”®å­—æ®µç´¢å¼•
  - `TeamMember.team_id`, `TeamMember.email`
  - `InviteRecord.team_id`, `InviteRecord.email`, `InviteRecord.status`, `InviteRecord.created_at`
  - `InviteQueue.status`
  - `RedeemCode.bound_email`

- **Alembic è¿ç§»**:
  - `007_add_performance_indexes.py`: å•åˆ—ç´¢å¼•
  - `008_add_composite_indexes.py`: å¤åˆç´¢å¼•

#### âœ… é˜¶æ®µäºŒï¼šæ¶æ„å‡çº§ï¼ˆåˆ†å¸ƒå¼æ”¯æŒï¼‰
- **celery_app.py**: Celery åº”ç”¨é…ç½®
  - åŸºäº Redis çš„æ¶ˆæ¯é˜Ÿåˆ—
  - è‡ªåŠ¨é‡è¯•å’Œè¶…æ—¶ä¿æŠ¤
  - å®šæ—¶ä»»åŠ¡æ”¯æŒ

- **tasks_celery.py**: Celery ä»»åŠ¡å®šä¹‰
  - `process_invite_task`: å¼‚æ­¥å¤„ç†é‚€è¯·
  - `sync_redeem_count_task`: åŒæ­¥ Redis åˆ°æ•°æ®åº“
  - `batch_sync_redeem_counts`: æ‰¹é‡åŒæ­¥å®šæ—¶ä»»åŠ¡
  - `cleanup_old_invite_queue`: æ¸…ç†æ—§è®°å½•

#### âœ… é˜¶æ®µä¸‰ï¼šæ€§èƒ½ä¼˜åŒ–
- **redeem_limiter.py**: Redis ä»¤ç‰Œæ¡¶é™æµå™¨
  - è§£å†³ RedeemCode çƒ­ç‚¹é—®é¢˜
  - Lua è„šæœ¬åŸå­æ€§æ‰£å‡
  - å¼‚æ­¥å›å†™æ•°æ®åº“

- **distributed_limiter.py**: åˆ†å¸ƒå¼é™æµå™¨
  - æ›¿ä»£è¿›ç¨‹å†… Semaphore
  - åŸºäº Redis çš„å…¨å±€å¹¶å‘æ§åˆ¶
  - é€Ÿç‡é™åˆ¶å™¨ï¼ˆæ»‘åŠ¨çª—å£ç®—æ³•ï¼‰

#### âœ… é˜¶æ®µå››ï¼šç›‘æ§å®Œå–„
- **metrics.py**: Prometheus ç›‘æ§æŒ‡æ ‡
  - ä¸šåŠ¡æŒ‡æ ‡ï¼ˆå…‘æ¢æˆåŠŸç‡ã€é˜Ÿåˆ—é•¿åº¦ï¼‰
  - æ€§èƒ½æŒ‡æ ‡ï¼ˆè¯·æ±‚å»¶è¿Ÿã€æ•°æ®åº“æŸ¥è¯¢æ—¶é—´ï¼‰
  - èµ„æºæŒ‡æ ‡ï¼ˆå¯ç”¨åº§ä½ã€è¿æ¥æ± ä½¿ç”¨ç‡ï¼‰
  - é”™è¯¯æŒ‡æ ‡ï¼ˆå¤±è´¥æ¬¡æ•°ã€é‡è¯•æ¬¡æ•°ï¼‰

---

## ğŸš€ éƒ¨ç½²æ­¥éª¤

### 1. æ›´æ–°ä¾èµ–

```bash
cd backend
pip install -r requirements-celery.txt
```

### 2. åº”ç”¨æ•°æ®åº“è¿ç§»

```bash
# æŸ¥çœ‹å¾…åº”ç”¨çš„è¿ç§»
alembic current
alembic history

# åº”ç”¨è¿ç§»
alembic upgrade head

# éªŒè¯ç´¢å¼•æ˜¯å¦åˆ›å»ºæˆåŠŸï¼ˆPostgreSQLï¼‰
psql -d invitehub -c "\d team_members"
psql -d invitehub -c "\d invite_records"
```

### 3. é…ç½®ç¯å¢ƒå˜é‡

åœ¨ `.env` æ–‡ä»¶ä¸­æ·»åŠ ï¼š

```env
# Redis é…ç½®
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_BROKER_DB=1
REDIS_BACKEND_DB=2

# Celery Worker é…ç½®
CELERY_CONCURRENCY=4  # Worker å¹¶å‘æ•°
CELERY_MAX_TASKS_PER_CHILD=1000
```

### 4. å¯åŠ¨ Celery Worker

```bash
# å¯åŠ¨ workerï¼ˆå•è¿›ç¨‹ï¼‰
celery -A app.celery_app worker --loglevel=info --concurrency=4

# å¯åŠ¨ workerï¼ˆå¤šè¿›ç¨‹ï¼Œæ¨èç”Ÿäº§ç¯å¢ƒï¼‰
celery -A app.celery_app worker --loglevel=info --concurrency=4 --pool=prefork

# å¯åŠ¨å®šæ—¶ä»»åŠ¡ï¼ˆCelery Beatï¼‰
celery -A app.celery_app beat --loglevel=info

# å¯åŠ¨ç›‘æ§ UIï¼ˆå¯é€‰ï¼‰
celery -A app.celery_app flower --port=5555
```

### 5. æ›´æ–° FastAPI åº”ç”¨

ä¿®æ”¹ `backend/app/routers/public.py`ï¼š

```python
# æ—§ä»£ç ï¼ˆasyncio é˜Ÿåˆ—ï¼‰
await enqueue_invite(email, redeem_code, group_id)

# æ–°ä»£ç ï¼ˆCelery ä»»åŠ¡ï¼‰
from app.tasks_celery import process_invite_task
process_invite_task.delay(email, redeem_code, group_id, is_rebind)
```

### 6. åˆå§‹åŒ– Redis ä»¤ç‰Œæ¡¶

åœ¨åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–æ‰€æœ‰æ´»è·ƒå…‘æ¢ç ï¼š

```python
# backend/app/main.py
from app.services.redeem_limiter import RedeemLimiter
from app.cache import get_redis
from app.models import RedeemCode

@app.on_event("startup")
async def startup_event():
    # åˆå§‹åŒ– Redis ä»¤ç‰Œæ¡¶
    redis_client = get_redis()
    if redis_client:
        limiter = RedeemLimiter(redis_client)
        db = SessionLocal()
        codes = db.query(RedeemCode).filter(RedeemCode.is_active == True).all()
        limiter.batch_init_codes([
            (c.code, c.max_uses, c.used_count) for c in codes
        ])
        db.close()
```

### 7. æ›´æ–°é™æµé€»è¾‘

ä¿®æ”¹ `backend/app/routers/public.py`ï¼š

```python
# æ—§ä»£ç ï¼ˆè¿›ç¨‹å†… Semaphoreï¼‰
async with _redeem_semaphore:
    return await _do_direct_redeem(data, db)

# æ–°ä»£ç ï¼ˆåˆ†å¸ƒå¼é™æµå™¨ï¼‰
from app.services.distributed_limiter import DistributedLimiter
from app.cache import get_redis

limiter = DistributedLimiter(
    get_redis(),
    key="global:redeem:limiter",
    max_concurrent=10
)

async with limiter:
    return await _do_direct_redeem(data, db)
```

### 8. é›†æˆ Prometheus

åœ¨ `backend/app/main.py` ä¸­æ·»åŠ ï¼š

```python
from prometheus_client import make_asgi_app

# åˆ›å»º Prometheus metrics ç«¯ç‚¹
metrics_app = make_asgi_app()
app.mount("/metrics", metrics_app)
```

---

## ğŸ§ª æµ‹è¯•éªŒè¯

### 1. æ•°æ®åº“ç´¢å¼•éªŒè¯

```sql
-- æŸ¥çœ‹ç´¢å¼•æ˜¯å¦åˆ›å»ºæˆåŠŸ
SELECT indexname, tablename
FROM pg_indexes
WHERE tablename IN ('team_members', 'invite_records', 'invite_queue', 'redeem_codes')
ORDER BY tablename, indexname;

-- æŸ¥çœ‹æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’ï¼ˆåº”ä½¿ç”¨ Index Scanï¼‰
EXPLAIN ANALYZE
SELECT * FROM invite_records
WHERE team_id = 1 AND status = 'success' AND created_at >= NOW() - INTERVAL '24 hours';
```

### 2. Celery ä»»åŠ¡æµ‹è¯•

```python
from app.tasks_celery import process_invite_task

# åŒæ­¥è°ƒç”¨ï¼ˆæµ‹è¯•ï¼‰
result = process_invite_task.apply(
    args=["test@example.com", "TESTCODE123"],
    kwargs={"group_id": 1, "is_rebind": False}
)
print(result.get())

# å¼‚æ­¥è°ƒç”¨ï¼ˆç”Ÿäº§ï¼‰
task = process_invite_task.delay("test@example.com", "TESTCODE123", 1, False)
print(f"Task ID: {task.id}")
print(f"Task status: {task.status}")
```

### 3. Redis ä»¤ç‰Œæ¡¶æµ‹è¯•

```python
from app.services.redeem_limiter import RedeemLimiter
from app.cache import get_redis

limiter = RedeemLimiter(get_redis())

# åˆå§‹åŒ–æµ‹è¯•å…‘æ¢ç 
limiter.init_code("TEST123", max_uses=10, used_count=0)

# æµ‹è¯•æ‰£å‡
for i in range(12):
    success = limiter.try_redeem("TEST123")
    print(f"Attempt {i+1}: {success}, remaining: {limiter.get_remaining('TEST123')}")
```

### 4. åˆ†å¸ƒå¼é™æµå™¨æµ‹è¯•

```python
from app.services.distributed_limiter import DistributedLimiter
from app.cache import get_redis
import asyncio

async def test_limiter():
    limiter = DistributedLimiter(
        get_redis(),
        key="test:limiter",
        max_concurrent=3
    )

    async with limiter:
        print(f"Current count: {limiter.get_current_count()}")
        await asyncio.sleep(2)

# è¿è¡Œ10ä¸ªå¹¶å‘ä»»åŠ¡
tasks = [test_limiter() for _ in range(10)]
asyncio.run(asyncio.gather(*tasks))
```

### 5. å‹åŠ›æµ‹è¯•

```bash
# ä½¿ç”¨ wrk è¿›è¡Œå‹åŠ›æµ‹è¯•
wrk -t 10 -c 100 -d 30s --latency http://localhost:4567/api/v1/public/direct-redeem

# ä½¿ç”¨ locust è¿›è¡Œå‹åŠ›æµ‹è¯•
pip install locust
locust -f tests/load_test.py --host=http://localhost:4567
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### ä¼˜åŒ–å‰
- **æœ€å¤§å¹¶å‘**: å•å®ä¾‹ï¼Œæ— æ³•æ°´å¹³æ‰©å±•
- **æ•°æ®åº“æŸ¥è¯¢**: å…¨è¡¨æ‰«æï¼Œéšæ•°æ®å¢é•¿çº¿æ€§ä¸‹é™
- **å…‘æ¢ç çƒ­ç‚¹**: è¡Œé”ç«äº‰ï¼Œååé‡ ~100 QPS
- **é˜Ÿåˆ—**: è¿›ç¨‹å†…ï¼Œå´©æºƒä¸¢å¤±

### ä¼˜åŒ–å
- **æœ€å¤§å¹¶å‘**: å¯éƒ¨ç½² 10+ å®ä¾‹ï¼Œç†è®ºæ— ä¸Šé™
- **æ•°æ®åº“æŸ¥è¯¢**: ç´¢å¼•æ‰«æï¼ŒO(log n) å¤æ‚åº¦
- **å…‘æ¢ç çƒ­ç‚¹**: Redis ä»¤ç‰Œæ¡¶ï¼Œååé‡ ~10000 QPS
- **é˜Ÿåˆ—**: æŒä¹…åŒ–ï¼Œè‡ªåŠ¨é‡è¯•ï¼Œå¯é æ€§ 99.9%

---

## ğŸ” ç›‘æ§å’Œå‘Šè­¦

### Grafana Dashboard

ç›‘æ§æŒ‡æ ‡å·²é€šè¿‡ `/metrics` ç«¯ç‚¹æš´éœ²ï¼Œå¯å¯¼å…¥ä»¥ä¸‹ Dashboardï¼š

1. **ä¸šåŠ¡æŒ‡æ ‡**:
   - å…‘æ¢æˆåŠŸç‡è¶‹åŠ¿
   - é˜Ÿåˆ—é•¿åº¦å®æ—¶ç›‘æ§
   - å¯ç”¨åº§ä½é¢„è­¦

2. **æ€§èƒ½æŒ‡æ ‡**:
   - P50/P95/P99 å»¶è¿Ÿ
   - æ•°æ®åº“æŸ¥è¯¢æ—¶é—´åˆ†å¸ƒ
   - Celery ä»»åŠ¡æ‰§è¡Œæ—¶é—´

3. **å‘Šè­¦è§„åˆ™**:
   ```yaml
   # prometheus.yml
   - alert: HighRedeemFailureRate
     expr: rate(redeem_requests_total{status="failed"}[5m]) > 0.1
     annotations:
       summary: "å…‘æ¢å¤±è´¥ç‡è¿‡é«˜: {{ $value }}"

   - alert: LowAvailableSeats
     expr: available_seats_total < 10
     annotations:
       summary: "å¯ç”¨åº§ä½ä¸è¶³: {{ $value }}"

   - alert: LongQueueSize
     expr: invite_queue_size{status="pending"} > 1000
     annotations:
       summary: "é˜Ÿåˆ—ç§¯å‹: {{ $value }} ä¸ªå¾…å¤„ç†ä»»åŠ¡"
   ```

### Flower ç›‘æ§

è®¿é—® `http://localhost:5555` æŸ¥çœ‹ï¼š
- å®æ—¶ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€
- Worker å¥åº·çŠ¶å†µ
- ä»»åŠ¡é‡è¯•å’Œå¤±è´¥ç»Ÿè®¡

---

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜ï¼šCelery Worker æ— æ³•è¿æ¥ Redis
```bash
# æ£€æŸ¥ Redis è¿æ¥
redis-cli -h localhost -p 6379 ping

# æ£€æŸ¥ Celery é…ç½®
celery -A app.celery_app inspect ping
```

### é—®é¢˜ï¼šæ•°æ®åº“è¿ç§»å¤±è´¥
```bash
# æŸ¥çœ‹å½“å‰ç‰ˆæœ¬
alembic current

# æ‰‹åŠ¨æ‰§è¡Œ SQL
psql -d invitehub -c "CREATE INDEX CONCURRENTLY ix_team_members_team_id ON team_members(team_id);"
```

### é—®é¢˜ï¼šRedis ä»¤ç‰Œæ¡¶ä¸å‡†ç¡®
```bash
# å¼ºåˆ¶åŒæ­¥æ‰€æœ‰å…‘æ¢ç 
celery -A app.celery_app call app.tasks_celery.batch_sync_redeem_counts
```

---

## ğŸ“š è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®

### çŸ­æœŸï¼ˆ1-2å‘¨ï¼‰
1. âœ… å®ç° SeatCalculator Redis ç¼“å­˜
2. âœ… æ·»åŠ æ…¢æŸ¥è¯¢æ—¥å¿—
3. âœ… å®ç°è¯·æ±‚è¿½è¸ªï¼ˆOpenTelemetryï¼‰

### ä¸­æœŸï¼ˆ1ä¸ªæœˆï¼‰
1. âœ… ç‰©åŒ–è§†å›¾ï¼ˆteam_seat_statsï¼‰
2. âœ… æ•°æ®å½’æ¡£ï¼ˆ90å¤©ä»¥ä¸Šçš„ InviteRecordï¼‰
3. âœ… æ•°æ®åº“è¯»å†™åˆ†ç¦»

### é•¿æœŸï¼ˆå­£åº¦çº§ï¼‰
1. âœ… æ•°æ®åº“åˆ†åŒºï¼ˆæŒ‰æœˆåˆ†åŒºï¼‰
2. âœ… CDN åŠ é€Ÿå‰ç«¯
3. âœ… å¤šåŒºåŸŸéƒ¨ç½²

---

## ğŸ¯ é¢„æœŸæ•ˆæœ

å®æ–½å®Œæˆåï¼Œç³»ç»Ÿæ€§èƒ½å°†æå‡è‡³ï¼š

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| æœ€å¤§å¹¶å‘ | 10 QPS | 5000+ QPS | **500x** |
| æ•°æ®åº“æŸ¥è¯¢ | 100ms+ | <10ms | **10x** |
| å…‘æ¢ç åå | 100 QPS | 10000 QPS | **100x** |
| ç³»ç»Ÿå¯ç”¨æ€§ | 99% | 99.9% | **0.9%** |
| æ¨ªå‘æ‰©å±• | âŒ | âœ… | **æ— é™** |

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒï¼š
- [Celery å®˜æ–¹æ–‡æ¡£](https://docs.celeryproject.org/)
- [Prometheus æ–‡æ¡£](https://prometheus.io/docs/)
- [PostgreSQL ç´¢å¼•ä¼˜åŒ–](https://www.postgresql.org/docs/current/indexes.html)
